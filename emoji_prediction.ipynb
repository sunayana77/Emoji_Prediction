{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,SimpleRNN,Embedding\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French macaroon is so tasty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am upset</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>throw the ball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0   1\n",
       "0  French macaroon is so tasty   4\n",
       "1             work is horrible   3\n",
       "2                   I am upset  3 \n",
       "3               throw the ball  1 \n",
       "4                    Good joke   2"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('emoji_data.csv',header = None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❤️'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":red_heart:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    0:\":red_heart:\",\n",
    "    1:\":baseball:\",\n",
    "    2:\":grinning_face_with_big_eyes:\",\n",
    "    3:\":disappointed_face:\",\n",
    "    4:\":fork_and_knife_plate:\"\n",
    "}\n",
    "\n",
    "def emoji_to_label(label):\n",
    "    return  emoji.emojize(emoji_dict[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0].values\n",
    "Y = data[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('glove.6B.100d.txt','r',encoding='utf8')\n",
    "content = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "\n",
    "for line in content:\n",
    "    line = line.split()\n",
    "    embeddings[line[0]]=np.array(line[1:],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'you': 2,\n",
       " 'is': 3,\n",
       " 'the': 4,\n",
       " 'a': 5,\n",
       " 'so': 6,\n",
       " 'am': 7,\n",
       " 'my': 8,\n",
       " 'to': 9,\n",
       " 'this': 10,\n",
       " 'are': 11,\n",
       " 'ha': 12,\n",
       " 'for': 13,\n",
       " 'she': 14,\n",
       " 'he': 15,\n",
       " 'me': 16,\n",
       " 'not': 17,\n",
       " 'love': 18,\n",
       " 'your': 19,\n",
       " 'want': 20,\n",
       " 'have': 21,\n",
       " 'it': 22,\n",
       " 'got': 23,\n",
       " 'like': 24,\n",
       " 'did': 25,\n",
       " 'baseball': 26,\n",
       " 'food': 27,\n",
       " 'was': 28,\n",
       " 'do': 29,\n",
       " 'joke': 30,\n",
       " 'stop': 31,\n",
       " 'will': 32,\n",
       " 'miss': 33,\n",
       " 'life': 34,\n",
       " 'ball': 35,\n",
       " 'good': 36,\n",
       " 'what': 37,\n",
       " 'go': 38,\n",
       " 'job': 39,\n",
       " 'funny': 40,\n",
       " 'bad': 41,\n",
       " 'day': 42,\n",
       " 'great': 43,\n",
       " 'dinner': 44,\n",
       " 'that': 45,\n",
       " 'with': 46,\n",
       " 'at': 47,\n",
       " 'of': 48,\n",
       " 'game': 49,\n",
       " 'we': 50,\n",
       " 'again': 51,\n",
       " 'said': 52,\n",
       " 'yes': 53,\n",
       " 'lol': 54,\n",
       " 'and': 55,\n",
       " 'down': 56,\n",
       " 'had': 57,\n",
       " 'her': 58,\n",
       " 'fun': 59,\n",
       " 'smile': 60,\n",
       " 'lot': 61,\n",
       " 'working': 62,\n",
       " 'him': 63,\n",
       " 'cute': 64,\n",
       " 'on': 65,\n",
       " 'lets': 66,\n",
       " 'messing': 67,\n",
       " 'us': 68,\n",
       " 'play': 69,\n",
       " 'exercise': 70,\n",
       " 'lost': 71,\n",
       " 'never': 72,\n",
       " 'where': 73,\n",
       " 'can': 74,\n",
       " 'well': 75,\n",
       " 'much': 76,\n",
       " 'valentine': 77,\n",
       " 'restaurant': 78,\n",
       " 'awesome': 79,\n",
       " 'likes': 80,\n",
       " 'such': 81,\n",
       " 'shouting': 82,\n",
       " 'proud': 83,\n",
       " 'bravo': 84,\n",
       " 'two': 85,\n",
       " 'forever': 86,\n",
       " 'grader': 87,\n",
       " 'dogs': 88,\n",
       " 'no': 89,\n",
       " 'girl': 90,\n",
       " 'excited': 91,\n",
       " 'by': 92,\n",
       " 'happy': 93,\n",
       " 'eat': 94,\n",
       " 'see': 95,\n",
       " 'long': 96,\n",
       " 'too': 97,\n",
       " 'congratulations': 98,\n",
       " 'answer': 99,\n",
       " 'just': 100,\n",
       " 'baby': 101,\n",
       " 'dance': 102,\n",
       " 'french': 103,\n",
       " 'macaroon': 104,\n",
       " 'tasty': 105,\n",
       " 'work': 106,\n",
       " 'horrible': 107,\n",
       " 'upset': 108,\n",
       " 'throw': 109,\n",
       " 'favorite': 110,\n",
       " 'cooked': 111,\n",
       " 'meat': 112,\n",
       " 'around': 113,\n",
       " 'chinese': 114,\n",
       " 'let': 115,\n",
       " 'failing': 116,\n",
       " 'yesterday': 117,\n",
       " 'cheese': 118,\n",
       " 'cake': 119,\n",
       " 'why': 120,\n",
       " 'feeling': 121,\n",
       " 'party': 122,\n",
       " 'cancelled': 123,\n",
       " 'frustrated': 124,\n",
       " 'raise': 125,\n",
       " 'family': 126,\n",
       " 'all': 127,\n",
       " 'pitch': 128,\n",
       " 'really': 129,\n",
       " 'stars': 130,\n",
       " 'back': 131,\n",
       " 'pizza': 132,\n",
       " 'totally': 133,\n",
       " 'deserve': 134,\n",
       " 'prize': 135,\n",
       " 'jacket': 136,\n",
       " 'present': 137,\n",
       " 'be': 138,\n",
       " 'failed': 139,\n",
       " 'midterm': 140,\n",
       " 'who': 141,\n",
       " 'near': 142,\n",
       " 'anything': 143,\n",
       " 'lovely': 144,\n",
       " 'tonight': 145,\n",
       " 'vegetables': 146,\n",
       " 'healthy': 147,\n",
       " 'friend': 148,\n",
       " 'talk': 149,\n",
       " 'having': 150,\n",
       " 'cannot': 151,\n",
       " 'come': 152,\n",
       " 'join': 153,\n",
       " 'an': 154,\n",
       " 'amazing': 155,\n",
       " 'taking': 156,\n",
       " 'breaks': 157,\n",
       " 'incredibly': 158,\n",
       " 'intelligent': 159,\n",
       " 'talented': 160,\n",
       " 'achievements': 161,\n",
       " 'sad': 162,\n",
       " 'coming': 163,\n",
       " 'saying': 164,\n",
       " 'bullshit': 165,\n",
       " 'announcement': 166,\n",
       " 'traction': 167,\n",
       " 'specialization': 168,\n",
       " 'waiting': 169,\n",
       " 'hours': 170,\n",
       " 'takes': 171,\n",
       " 'get': 172,\n",
       " 'ready': 173,\n",
       " 'grandmother': 174,\n",
       " 'celebrate': 175,\n",
       " 'soon': 176,\n",
       " 'code': 177,\n",
       " 'but': 178,\n",
       " 'gave': 179,\n",
       " 'zero': 180,\n",
       " 'cutest': 181,\n",
       " 'person': 182,\n",
       " 'ever': 183,\n",
       " 'seen': 184,\n",
       " 'laughing': 185,\n",
       " 'adore': 186,\n",
       " 'mum': 187,\n",
       " 'how': 188,\n",
       " 'dare': 189,\n",
       " 'ask': 190,\n",
       " 'guy': 191,\n",
       " 'indian': 192,\n",
       " 'afternoon': 193,\n",
       " 'stupidity': 194,\n",
       " 'has': 195,\n",
       " 'limit': 196,\n",
       " 'dad': 197,\n",
       " 'give': 198,\n",
       " 'hug': 199,\n",
       " 'mean': 200,\n",
       " 'wrong': 201,\n",
       " 'they': 202,\n",
       " 'kind': 203,\n",
       " 'friendly': 204,\n",
       " 'impressed': 205,\n",
       " 'dedication': 206,\n",
       " 'project': 207,\n",
       " 'made': 208,\n",
       " 'ordering': 209,\n",
       " 'sounds': 210,\n",
       " 'plan': 211,\n",
       " 'killing': 212,\n",
       " 'haha': 213,\n",
       " 'qualified': 214,\n",
       " 'position': 215,\n",
       " 'dear': 216,\n",
       " 'after': 217,\n",
       " 'best': 218,\n",
       " 'player': 219,\n",
       " 'moment': 220,\n",
       " 'algorithm': 221,\n",
       " 'performs': 222,\n",
       " 'poorly': 223,\n",
       " 'charming': 224,\n",
       " 'worst': 225,\n",
       " 'in': 226,\n",
       " 'handsome': 227,\n",
       " 'one': 228,\n",
       " 'attractive': 229,\n",
       " 'exam': 230,\n",
       " 'think': 231,\n",
       " 'end': 232,\n",
       " 'up': 233,\n",
       " 'alone': 234,\n",
       " 'together': 235,\n",
       " 'were': 236,\n",
       " 'here': 237,\n",
       " 'loser': 238,\n",
       " 'starving': 239,\n",
       " 'suck': 240,\n",
       " 'could': 241,\n",
       " 'solve': 242,\n",
       " 'wallet': 243,\n",
       " 'text': 244,\n",
       " 'catcher': 245,\n",
       " 'sucks': 246,\n",
       " 'boiled': 247,\n",
       " 'rice': 248,\n",
       " 'candy': 249,\n",
       " 'finished': 250,\n",
       " 'first': 251,\n",
       " 'base': 252,\n",
       " 'man': 253,\n",
       " 'acceptance': 254,\n",
       " 'assignment': 255,\n",
       " 'humiliated': 256,\n",
       " 'sister': 257,\n",
       " 'lectures': 258,\n",
       " 'though': 259,\n",
       " 'homework': 260,\n",
       " 'adorable': 261,\n",
       " 'missed': 262,\n",
       " 'looking': 263,\n",
       " 'date': 264,\n",
       " 'awful': 265,\n",
       " 'any': 266,\n",
       " 'suggestions': 267,\n",
       " 'always': 268,\n",
       " 'grade': 269,\n",
       " 'sushi': 270,\n",
       " 'smiles': 271,\n",
       " 'chicago': 272,\n",
       " 'cubs': 273,\n",
       " 'won': 274,\n",
       " 'approved': 275,\n",
       " 'cookies': 276,\n",
       " 'hate': 277,\n",
       " 'going': 278,\n",
       " 'stadium': 279,\n",
       " 'very': 280,\n",
       " 'disappointed': 281,\n",
       " 'congrats': 282,\n",
       " 'new': 283,\n",
       " 'enjoy': 284,\n",
       " 'break': 285,\n",
       " 'away': 286,\n",
       " 'worked': 287,\n",
       " 'during': 288,\n",
       " 'birthday': 289,\n",
       " 'congratulation': 290,\n",
       " 'fon': 291,\n",
       " 'hungry': 292,\n",
       " 'dearest': 293,\n",
       " 'breakfast': 294,\n",
       " 'dog': 295,\n",
       " 'few': 296,\n",
       " 'puppies': 297,\n",
       " 'make': 298,\n",
       " 'home': 299,\n",
       " 'run': 300,\n",
       " 'serious': 301,\n",
       " 'laugh': 302,\n",
       " 'making': 303,\n",
       " 'stupid': 304,\n",
       " 'boring': 305,\n",
       " 'brighten': 306,\n",
       " 'brunch': 307,\n",
       " 'some': 308,\n",
       " 'bully': 309,\n",
       " 'plays': 310,\n",
       " 'when': 311,\n",
       " 'people': 312}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word2index = tokenizer.word_index\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Y to numeric, remove NaN values, and drop corresponding X values\n",
    "Y = pd.Series(Y)\n",
    "Y = pd.to_numeric(Y, errors='coerce')  # Coerce errors to NaN\n",
    "X = X[Y.notna()]  # Remove the corresponding X values where Y is NaN\n",
    "Y = Y.dropna().astype(int)  # Remove NaN from Y and convert to integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtokens = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[103, 104, 3, 6, 105],\n",
       " [106, 3, 107],\n",
       " [1, 7, 108],\n",
       " [109, 4, 35],\n",
       " [36, 30],\n",
       " [37, 3, 19, 110, 26, 49],\n",
       " [1, 111, 112],\n",
       " [31, 67, 113],\n",
       " [1, 20, 114, 27],\n",
       " [115, 68, 38, 69, 26],\n",
       " [2, 11, 116, 10, 70],\n",
       " [117, 50, 71, 51],\n",
       " [36, 39],\n",
       " [12, 12, 12, 22, 28, 6, 40],\n",
       " [1, 32, 21, 5, 118, 119],\n",
       " [120, 11, 2, 121, 41],\n",
       " [1, 20, 9, 30],\n",
       " [1, 72, 52, 53, 13, 10],\n",
       " [4, 122, 3, 123],\n",
       " [73, 3, 4, 35],\n",
       " [1, 7, 124],\n",
       " [12, 12, 12, 54],\n",
       " [14, 52, 53],\n",
       " [15, 23, 5, 125],\n",
       " [126, 3, 127, 1, 21],\n",
       " [15, 74, 128, 129, 75],\n",
       " [1, 18, 9, 4, 130, 55, 131],\n",
       " [29, 2, 24, 132],\n",
       " [2, 133, 134, 10, 135],\n",
       " [1, 24, 19, 136],\n",
       " [14, 23, 16, 5, 137],\n",
       " [32, 2, 138, 8, 77],\n",
       " [2, 139, 4, 140],\n",
       " [141, 3, 56, 13, 5, 78],\n",
       " [77, 42, 3, 142],\n",
       " [43, 6, 79],\n",
       " [29, 2, 21, 5, 35],\n",
       " [15, 74, 17, 29, 143],\n",
       " [15, 80, 26],\n",
       " [50, 57, 81, 5, 144, 44, 145],\n",
       " [146, 11, 147],\n",
       " [15, 3, 5, 36, 148],\n",
       " [72, 149, 9, 16, 51],\n",
       " [1, 33, 58],\n",
       " [27, 3, 34],\n",
       " [1, 7, 150, 59],\n",
       " [6, 41, 45, 2, 151, 152, 46, 68],\n",
       " [29, 2, 20, 9, 153, 16, 13, 44],\n",
       " [1, 24, 9, 60],\n",
       " [15, 25, 154, 155, 39],\n",
       " [31, 82, 47, 16],\n",
       " [1, 18, 156, 157],\n",
       " [2, 11, 158, 159, 55, 160],\n",
       " [1, 7, 83, 48, 19, 161],\n",
       " [6, 162, 2, 11, 17, 163],\n",
       " [40],\n",
       " [31, 164, 165],\n",
       " [84, 13, 4, 166, 22, 23, 5, 61, 48, 167],\n",
       " [10, 168, 3, 43],\n",
       " [1, 28, 169, 13, 58, 13, 85, 170],\n",
       " [14, 171, 86, 9, 172, 173],\n",
       " [8, 174, 3, 4, 18, 48, 8, 34],\n",
       " [1, 32, 175, 176],\n",
       " [8, 177, 3, 62, 178, 4, 87, 179, 16, 180],\n",
       " [14, 3, 4, 181, 182, 1, 21, 183, 184],\n",
       " [15, 3, 185],\n",
       " [1, 186, 8, 88],\n",
       " [1, 18, 2, 187],\n",
       " [43, 39],\n",
       " [188, 189, 2, 190, 45],\n",
       " [10, 191, 28, 81, 5, 30],\n",
       " [1, 18, 192, 27],\n",
       " [11, 2, 56, 13, 26, 10, 193],\n",
       " [10, 3, 41],\n",
       " [19, 194, 195, 89, 196],\n",
       " [1, 18, 8, 197],\n",
       " [29, 2, 20, 9, 198, 16, 5, 199],\n",
       " [10, 90, 28, 200],\n",
       " [1, 7, 91],\n",
       " [1, 33, 63],\n",
       " [37, 3, 201, 46, 2],\n",
       " [202, 11, 6, 203, 55, 204],\n",
       " [1, 7, 6, 205, 92, 19, 206, 9, 10, 207],\n",
       " [50, 208, 22],\n",
       " [1, 7, 209, 27],\n",
       " [210, 24, 5, 59, 211, 12, 12],\n",
       " [1, 7, 6, 93, 13, 2],\n",
       " [33, 2, 6, 76],\n",
       " [1, 18, 2],\n",
       " [10, 30, 3, 212, 16, 213],\n",
       " [2, 11, 17, 214, 13, 10, 215],\n",
       " [33, 2, 8, 216],\n",
       " [1, 20, 9, 94],\n",
       " [1, 7, 6, 91, 9, 95, 2, 217, 6, 96],\n",
       " [15, 3, 4, 218, 219],\n",
       " [37, 5, 59, 220],\n",
       " [8, 221, 222, 223],\n",
       " [31, 82, 47, 16],\n",
       " [58, 60, 3, 6, 224],\n",
       " [22, 3, 4, 225, 42, 226, 8, 34],\n",
       " [15, 3, 227],\n",
       " [89, 228, 80, 63],\n",
       " [14, 3, 229],\n",
       " [22, 28, 40, 54],\n",
       " [15, 3, 6, 64],\n",
       " [2, 25, 75, 65, 2, 230],\n",
       " [1, 231, 1, 32, 232, 233, 234],\n",
       " [66, 21, 27, 235],\n",
       " [97, 41, 45, 2, 236, 17, 237],\n",
       " [1, 20, 9, 38, 69],\n",
       " [2, 11, 5, 238],\n",
       " [1, 7, 239],\n",
       " [2, 240],\n",
       " [98],\n",
       " [2, 241, 17, 242, 22],\n",
       " [1, 71, 8, 243],\n",
       " [14, 25, 17, 99, 8, 244],\n",
       " [45, 245, 246],\n",
       " [95, 2, 47, 4, 78],\n",
       " [1, 247, 248],\n",
       " [1, 52, 53],\n",
       " [249, 3, 34],\n",
       " [4, 49, 100, 250],\n",
       " [4, 251, 252, 253, 23, 4, 35],\n",
       " [98, 65, 19, 254],\n",
       " [4, 255, 3, 97, 96],\n",
       " [54],\n",
       " [1, 23, 256, 92, 8, 257],\n",
       " [1, 20, 9, 94],\n",
       " [4, 258, 11, 43, 259],\n",
       " [2, 25, 17, 29, 19, 260],\n",
       " [4, 101, 3, 261],\n",
       " [84],\n",
       " [1, 262, 2],\n",
       " [1, 7, 263, 13, 5, 264],\n",
       " [73, 3, 4, 27],\n",
       " [2, 11, 265],\n",
       " [266, 267, 13, 44],\n",
       " [14, 3, 93],\n",
       " [1, 7, 268, 62],\n",
       " [10, 3, 6, 40],\n",
       " [2, 23, 5, 56, 269],\n",
       " [1, 20, 9, 21, 270, 13, 44],\n",
       " [14, 271, 5, 61],\n",
       " [4, 272, 273, 274, 51],\n",
       " [1, 23, 275],\n",
       " [276, 11, 36],\n",
       " [1, 277, 63],\n",
       " [1, 7, 278, 9, 4, 279],\n",
       " [1, 7, 280, 281],\n",
       " [1, 7, 83, 48, 2, 86],\n",
       " [10, 90, 3, 67, 46, 16],\n",
       " [282, 65, 4, 283, 39],\n",
       " [284, 19, 285],\n",
       " [38, 286],\n",
       " [1, 287, 288, 8, 289],\n",
       " [290, 291, 21, 5, 101],\n",
       " [1, 7, 292],\n",
       " [14, 3, 8, 293, 18],\n",
       " [14, 3, 6, 64],\n",
       " [1, 18, 88],\n",
       " [1, 25, 17, 21, 294],\n",
       " [8, 295, 100, 57, 5, 296, 297],\n",
       " [1, 24, 2, 5, 61],\n",
       " [15, 57, 9, 298, 5, 299, 300],\n",
       " [1, 7, 47, 4, 26, 49],\n",
       " [11, 2, 301, 12, 12],\n",
       " [1, 24, 9, 302],\n",
       " [31, 303, 10, 30, 12, 12, 12],\n",
       " [2, 85, 11, 64],\n",
       " [10, 304, 87, 3, 17, 62],\n",
       " [37, 2, 25, 28, 79],\n",
       " [8, 34, 3, 6, 305],\n",
       " [15, 25, 17, 99],\n",
       " [66, 70],\n",
       " [2, 306, 8, 42],\n",
       " [1, 32, 38, 102],\n",
       " [66, 307, 308, 42],\n",
       " [102, 46, 16],\n",
       " [14, 3, 5, 309],\n",
       " [14, 310, 26],\n",
       " [1, 24, 22, 311, 312, 60]]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def get_maxlen(data):\n",
    "    return max(len(sent) for sent in data)\n",
    "\n",
    "maxlen = get_maxlen(Xtokens)\n",
    "print(maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103, 104,   3, ...,   0,   0,   0],\n",
       "       [106,   3, 107, ...,   0,   0,   0],\n",
       "       [  1,   7, 108, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 14,   3,   5, ...,   0,   0,   0],\n",
       "       [ 14, 310,  26, ...,   0,   0,   0],\n",
       "       [  1,  24,  22, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = pad_sequences(Xtokens,maxlen=10,padding='post',truncating='post')\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain = to_categorical(Y)\n",
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Xtrain: (182, 10)\n",
      "Shape of Ytrain: (182, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Xtrain:\", Xtrain.shape)\n",
    "print(\"Shape of Ytrain:\", Ytrain.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'you': 2,\n",
       " 'is': 3,\n",
       " 'the': 4,\n",
       " 'a': 5,\n",
       " 'so': 6,\n",
       " 'am': 7,\n",
       " 'my': 8,\n",
       " 'to': 9,\n",
       " 'this': 10,\n",
       " 'are': 11,\n",
       " 'ha': 12,\n",
       " 'for': 13,\n",
       " 'she': 14,\n",
       " 'he': 15,\n",
       " 'me': 16,\n",
       " 'not': 17,\n",
       " 'love': 18,\n",
       " 'your': 19,\n",
       " 'want': 20,\n",
       " 'have': 21,\n",
       " 'it': 22,\n",
       " 'got': 23,\n",
       " 'like': 24,\n",
       " 'did': 25,\n",
       " 'baseball': 26,\n",
       " 'food': 27,\n",
       " 'was': 28,\n",
       " 'do': 29,\n",
       " 'joke': 30,\n",
       " 'stop': 31,\n",
       " 'will': 32,\n",
       " 'miss': 33,\n",
       " 'life': 34,\n",
       " 'ball': 35,\n",
       " 'good': 36,\n",
       " 'what': 37,\n",
       " 'go': 38,\n",
       " 'job': 39,\n",
       " 'funny': 40,\n",
       " 'bad': 41,\n",
       " 'day': 42,\n",
       " 'great': 43,\n",
       " 'dinner': 44,\n",
       " 'that': 45,\n",
       " 'with': 46,\n",
       " 'at': 47,\n",
       " 'of': 48,\n",
       " 'game': 49,\n",
       " 'we': 50,\n",
       " 'again': 51,\n",
       " 'said': 52,\n",
       " 'yes': 53,\n",
       " 'lol': 54,\n",
       " 'and': 55,\n",
       " 'down': 56,\n",
       " 'had': 57,\n",
       " 'her': 58,\n",
       " 'fun': 59,\n",
       " 'smile': 60,\n",
       " 'lot': 61,\n",
       " 'working': 62,\n",
       " 'him': 63,\n",
       " 'cute': 64,\n",
       " 'on': 65,\n",
       " 'lets': 66,\n",
       " 'messing': 67,\n",
       " 'us': 68,\n",
       " 'play': 69,\n",
       " 'exercise': 70,\n",
       " 'lost': 71,\n",
       " 'never': 72,\n",
       " 'where': 73,\n",
       " 'can': 74,\n",
       " 'well': 75,\n",
       " 'much': 76,\n",
       " 'valentine': 77,\n",
       " 'restaurant': 78,\n",
       " 'awesome': 79,\n",
       " 'likes': 80,\n",
       " 'such': 81,\n",
       " 'shouting': 82,\n",
       " 'proud': 83,\n",
       " 'bravo': 84,\n",
       " 'two': 85,\n",
       " 'forever': 86,\n",
       " 'grader': 87,\n",
       " 'dogs': 88,\n",
       " 'no': 89,\n",
       " 'girl': 90,\n",
       " 'excited': 91,\n",
       " 'by': 92,\n",
       " 'happy': 93,\n",
       " 'eat': 94,\n",
       " 'see': 95,\n",
       " 'long': 96,\n",
       " 'too': 97,\n",
       " 'congratulations': 98,\n",
       " 'answer': 99,\n",
       " 'just': 100,\n",
       " 'baby': 101,\n",
       " 'dance': 102,\n",
       " 'french': 103,\n",
       " 'macaroon': 104,\n",
       " 'tasty': 105,\n",
       " 'work': 106,\n",
       " 'horrible': 107,\n",
       " 'upset': 108,\n",
       " 'throw': 109,\n",
       " 'favorite': 110,\n",
       " 'cooked': 111,\n",
       " 'meat': 112,\n",
       " 'around': 113,\n",
       " 'chinese': 114,\n",
       " 'let': 115,\n",
       " 'failing': 116,\n",
       " 'yesterday': 117,\n",
       " 'cheese': 118,\n",
       " 'cake': 119,\n",
       " 'why': 120,\n",
       " 'feeling': 121,\n",
       " 'party': 122,\n",
       " 'cancelled': 123,\n",
       " 'frustrated': 124,\n",
       " 'raise': 125,\n",
       " 'family': 126,\n",
       " 'all': 127,\n",
       " 'pitch': 128,\n",
       " 'really': 129,\n",
       " 'stars': 130,\n",
       " 'back': 131,\n",
       " 'pizza': 132,\n",
       " 'totally': 133,\n",
       " 'deserve': 134,\n",
       " 'prize': 135,\n",
       " 'jacket': 136,\n",
       " 'present': 137,\n",
       " 'be': 138,\n",
       " 'failed': 139,\n",
       " 'midterm': 140,\n",
       " 'who': 141,\n",
       " 'near': 142,\n",
       " 'anything': 143,\n",
       " 'lovely': 144,\n",
       " 'tonight': 145,\n",
       " 'vegetables': 146,\n",
       " 'healthy': 147,\n",
       " 'friend': 148,\n",
       " 'talk': 149,\n",
       " 'having': 150,\n",
       " 'cannot': 151,\n",
       " 'come': 152,\n",
       " 'join': 153,\n",
       " 'an': 154,\n",
       " 'amazing': 155,\n",
       " 'taking': 156,\n",
       " 'breaks': 157,\n",
       " 'incredibly': 158,\n",
       " 'intelligent': 159,\n",
       " 'talented': 160,\n",
       " 'achievements': 161,\n",
       " 'sad': 162,\n",
       " 'coming': 163,\n",
       " 'saying': 164,\n",
       " 'bullshit': 165,\n",
       " 'announcement': 166,\n",
       " 'traction': 167,\n",
       " 'specialization': 168,\n",
       " 'waiting': 169,\n",
       " 'hours': 170,\n",
       " 'takes': 171,\n",
       " 'get': 172,\n",
       " 'ready': 173,\n",
       " 'grandmother': 174,\n",
       " 'celebrate': 175,\n",
       " 'soon': 176,\n",
       " 'code': 177,\n",
       " 'but': 178,\n",
       " 'gave': 179,\n",
       " 'zero': 180,\n",
       " 'cutest': 181,\n",
       " 'person': 182,\n",
       " 'ever': 183,\n",
       " 'seen': 184,\n",
       " 'laughing': 185,\n",
       " 'adore': 186,\n",
       " 'mum': 187,\n",
       " 'how': 188,\n",
       " 'dare': 189,\n",
       " 'ask': 190,\n",
       " 'guy': 191,\n",
       " 'indian': 192,\n",
       " 'afternoon': 193,\n",
       " 'stupidity': 194,\n",
       " 'has': 195,\n",
       " 'limit': 196,\n",
       " 'dad': 197,\n",
       " 'give': 198,\n",
       " 'hug': 199,\n",
       " 'mean': 200,\n",
       " 'wrong': 201,\n",
       " 'they': 202,\n",
       " 'kind': 203,\n",
       " 'friendly': 204,\n",
       " 'impressed': 205,\n",
       " 'dedication': 206,\n",
       " 'project': 207,\n",
       " 'made': 208,\n",
       " 'ordering': 209,\n",
       " 'sounds': 210,\n",
       " 'plan': 211,\n",
       " 'killing': 212,\n",
       " 'haha': 213,\n",
       " 'qualified': 214,\n",
       " 'position': 215,\n",
       " 'dear': 216,\n",
       " 'after': 217,\n",
       " 'best': 218,\n",
       " 'player': 219,\n",
       " 'moment': 220,\n",
       " 'algorithm': 221,\n",
       " 'performs': 222,\n",
       " 'poorly': 223,\n",
       " 'charming': 224,\n",
       " 'worst': 225,\n",
       " 'in': 226,\n",
       " 'handsome': 227,\n",
       " 'one': 228,\n",
       " 'attractive': 229,\n",
       " 'exam': 230,\n",
       " 'think': 231,\n",
       " 'end': 232,\n",
       " 'up': 233,\n",
       " 'alone': 234,\n",
       " 'together': 235,\n",
       " 'were': 236,\n",
       " 'here': 237,\n",
       " 'loser': 238,\n",
       " 'starving': 239,\n",
       " 'suck': 240,\n",
       " 'could': 241,\n",
       " 'solve': 242,\n",
       " 'wallet': 243,\n",
       " 'text': 244,\n",
       " 'catcher': 245,\n",
       " 'sucks': 246,\n",
       " 'boiled': 247,\n",
       " 'rice': 248,\n",
       " 'candy': 249,\n",
       " 'finished': 250,\n",
       " 'first': 251,\n",
       " 'base': 252,\n",
       " 'man': 253,\n",
       " 'acceptance': 254,\n",
       " 'assignment': 255,\n",
       " 'humiliated': 256,\n",
       " 'sister': 257,\n",
       " 'lectures': 258,\n",
       " 'though': 259,\n",
       " 'homework': 260,\n",
       " 'adorable': 261,\n",
       " 'missed': 262,\n",
       " 'looking': 263,\n",
       " 'date': 264,\n",
       " 'awful': 265,\n",
       " 'any': 266,\n",
       " 'suggestions': 267,\n",
       " 'always': 268,\n",
       " 'grade': 269,\n",
       " 'sushi': 270,\n",
       " 'smiles': 271,\n",
       " 'chicago': 272,\n",
       " 'cubs': 273,\n",
       " 'won': 274,\n",
       " 'approved': 275,\n",
       " 'cookies': 276,\n",
       " 'hate': 277,\n",
       " 'going': 278,\n",
       " 'stadium': 279,\n",
       " 'very': 280,\n",
       " 'disappointed': 281,\n",
       " 'congrats': 282,\n",
       " 'new': 283,\n",
       " 'enjoy': 284,\n",
       " 'break': 285,\n",
       " 'away': 286,\n",
       " 'worked': 287,\n",
       " 'during': 288,\n",
       " 'birthday': 289,\n",
       " 'congratulation': 290,\n",
       " 'fon': 291,\n",
       " 'hungry': 292,\n",
       " 'dearest': 293,\n",
       " 'breakfast': 294,\n",
       " 'dog': 295,\n",
       " 'few': 296,\n",
       " 'puppies': 297,\n",
       " 'make': 298,\n",
       " 'home': 299,\n",
       " 'run': 300,\n",
       " 'serious': 301,\n",
       " 'laugh': 302,\n",
       " 'making': 303,\n",
       " 'stupid': 304,\n",
       " 'boring': 305,\n",
       " 'brighten': 306,\n",
       " 'brunch': 307,\n",
       " 'some': 308,\n",
       " 'bully': 309,\n",
       " 'plays': 310,\n",
       " 'when': 311,\n",
       " 'people': 312}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "embedding_matrix = np.zeros((len(word2index)+1, embed_size))\n",
    "\n",
    "for word, i in word2index.items():\n",
    "    embed_vector = embeddings[word]\n",
    "    embedding_matrix[i] = embed_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word2index)+1,\n",
    "              output_dim = embed_size,\n",
    "              input_length = maxlen,\n",
    "               weights = [embedding_matrix],\n",
    "               trainable = False),\n",
    "    LSTM(units=16,return_sequences=True ),\n",
    "    LSTM(units=10,return_sequences=True),\n",
    "    LSTM(units=8),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Xtrain: (182, 10)\n",
      "Shape of Ytrain: (182, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Xtrain:\", Xtrain.shape)\n",
    "print(\"Shape of Ytrain:\", Ytrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2225 - loss: 1.6075\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3206 - loss: 1.5929 \n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3612 - loss: 1.5719 \n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3234 - loss: 1.5582 \n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3036 - loss: 1.5476 \n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3263 - loss: 1.5259 \n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3208 - loss: 1.5168 \n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3493 - loss: 1.4979 \n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3884 - loss: 1.4849 \n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4119 - loss: 1.4660 \n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4916 - loss: 1.4023 \n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4681 - loss: 1.3671 \n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5286 - loss: 1.3059 \n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5815 - loss: 1.2400 \n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5827 - loss: 1.2015 \n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6202 - loss: 1.1445 \n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6351 - loss: 1.0998 \n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6116 - loss: 1.0729 \n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6771 - loss: 0.9522 \n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6335 - loss: 0.9515 \n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7151 - loss: 0.8657 \n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6752 - loss: 0.8921 \n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6715 - loss: 0.8434 \n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7579 - loss: 0.8468 \n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7856 - loss: 0.7244 \n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.6935 \n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.6577 \n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.6086 \n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.6143 \n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8398 - loss: 0.5878 \n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8903 - loss: 0.5434 \n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.5046 \n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.4553 \n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.4415 \n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.4457 \n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9333 - loss: 0.3993 \n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.4310 \n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9353 - loss: 0.3916 \n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9603 - loss: 0.3211\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.3624 \n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9552 - loss: 0.3382 \n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.3305 \n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9707 - loss: 0.3138 \n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.2723 \n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.2651 \n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.2566 \n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.2771 \n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.2308 \n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.2670 \n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.2694 \n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.2480 \n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.2472 \n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.2182 \n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.2113 \n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.1926 \n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.1965 \n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.2024 \n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9794 - loss: 0.1945 \n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.1755 \n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.1833 \n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.1935 \n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.1768 \n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.1514 \n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.1438 \n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.1512 \n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.1521 \n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.1719 \n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9851 - loss: 0.1380 \n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9842 - loss: 0.1421 \n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.1418 \n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.1471 \n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9685 - loss: 0.1679 \n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.2934 \n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1681 \n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9586 - loss: 0.2029 \n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9743 - loss: 0.1688 \n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9776 - loss: 0.1410 \n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.2086 \n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.1280 \n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.1363 \n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.1546 \n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.1397 \n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9771 - loss: 0.1288 \n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.1630 \n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.1197 \n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.1049 \n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.1283 \n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.1052 \n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.1250 \n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.1019 \n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.1022 \n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.1072 \n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0899 \n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0922 \n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0829 \n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0997 \n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0838 \n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.1155 \n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0898 \n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0770 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bce4b355a0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
      "i feel good 😃\n",
      "i feel very bad 😞\n",
      "i love you ❤️\n"
     ]
    }
   ],
   "source": [
    "test = [\"i feel good\",\"i feel very bad\",\"i love you\"]\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq,maxlen=maxlen,padding='post',truncating='post')\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    " \n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test[i],emoji_to_label(y_pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
